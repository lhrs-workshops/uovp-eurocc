{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD-P02Vu8m6p"
      },
      "source": [
        "# Pandas in velepodatki\n",
        "\n",
        "V tej enoti se boste seznanili z uporabo knjižnice Pandas na velikih količinah podatkov. Kot velepodatke smatramo podatke, ki lahko dosegajo velikosti več TB ali pa celo še več. Velepodatki obsegajo na milijone, milijarde ali več vrstic v datotekah CSV ali JSON. V teh primerih se ukvarjamo z izzivi hitrega nalaganja, branja, filtriranja, obdelovanja in shranjevanja podatkov. Ob tako velikih količinah podatkov je zelo pomembno, da uporabimo smiselne pristope za delo s podatki, saj nam to lahko prihrani ogromno časa pri obdelavi. V nadaljevanju bomo podrobneje predstavili delo z velepodatki in knjižnico Pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq6y9dhG8m6t"
      },
      "source": [
        "## Podatkovna zbirka KASANDR\n",
        "\n",
        "Pri nadaljnjem delu bomo uporabljali podatkovno zbirko KASANDR, ki je prostodostopna zbirka velepodatkov. Zajema nekaj čez 17 milijonov vrstic podatkov o ogledih artiklov na spletnih straneh Kelkoo.com. Podatkovna zbirka KASANDR je bila zasnovana za razvoj priporočilnih sistemov.\n",
        "\n",
        "Podatkovno zbirko najdemo v repozitoriju UCI Machine Learning (https://archive.ics.uci.edu/dataset/385/kasandr). Razdeljena je na testno in učno množico. Testna množica obsega skoraj 2 milijona vrstic in zaseda 381,3 MB, učna množica pa obsega skoraj 16 milijonov vrstic in zaseda 3,1 GB.\n",
        "\n",
        "S spodnjo kodo prenesemo podatkovno zbirko in jo razširimo na sistem. **Kodo je v nadaljevanju priporočljivo zaganjati v okolju [Google Colab](https://colab.research.google.com).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thPBd3eS8m6u",
        "outputId": "6f7adff0-7a02-4c22-9362-330711394faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prenos podatkovne zbirke KASANDR ...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  900M    0  900M    0     0  2906k      0 --:--:--  0:05:17 --:--:-- 11.3M\n",
            "Prenos končan!\n",
            "Razširjanje podatkovne zbirke KASANDR (korak 1/2) ...\n",
            "Archive:  kasandr.zip\n",
            " extracting: de.tar.bz2              \n",
            "Razširjanje podatkovne zbirke KASANDR (korak 2/2) ...\n",
            "./._de\n",
            "de/\n",
            "de/._test_de.csv\n",
            "de/test_de.csv\n",
            "de/._train_de.csv\n",
            "de/train_de.csv\n",
            "Razširjanje končano!\n"
          ]
        }
      ],
      "source": [
        "# Prenos podatkovne zbirke KASANDR (stisnjena: ~900MB, razširjena: 3.5GB; 17.764.280 vrstic, 7 stolpcev)\n",
        "# https://archive.ics.uci.edu/static/public/385/kasandr.zip\n",
        "\n",
        "print('Prenos podatkovne zbirke KASANDR ...')\n",
        "!curl https://archive.ics.uci.edu/static/public/385/kasandr.zip -o kasandr.zip\n",
        "print('Prenos končan!')\n",
        "\n",
        "print('Razširjanje podatkovne zbirke KASANDR (korak 1/2) ...')\n",
        "!unzip kasandr.zip\n",
        "print('Razširjanje podatkovne zbirke KASANDR (korak 2/2) ...')\n",
        "!tar -xvjf de.tar.bz2\n",
        "print('Razširjanje končano!')\n",
        "\n",
        "# počistimo začasne datoteke\n",
        "!rm -rf de.tar* kasandr.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "esL-IRPU8m6v"
      },
      "outputs": [],
      "source": [
        "# vključevanje potrebnih knjižnic\n",
        "import os\n",
        "import humanize\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hod6DooM8m6w",
        "outputId": "b680013d-db92-434b-9f84-f4d9cf4ac375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Velikosti datotek podatkovne zbirke KASANDR: \n",
            "- test_de.csv: 381.3 MB \n",
            "- train_de.csv: 3.1 GB\n"
          ]
        }
      ],
      "source": [
        "# preverimo velikost datotek\n",
        "size_test = os.path.getsize('de/test_de.csv')\n",
        "size_train = os.path.getsize('de/train_de.csv')\n",
        "\n",
        "print(f'Velikosti datotek podatkovne zbirke KASANDR: \\n- test_de.csv: {humanize.naturalsize(size_test)} \\n- train_de.csv: {humanize.naturalsize(size_train)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEdUCdf28m6x",
        "outputId": "54911e78-3da4-452a-f13a-da5ab934db52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 5.69 s, sys: 787 ms, total: 6.48 s\n",
            "Wall time: 6.49 s\n"
          ]
        }
      ],
      "source": [
        "# poskusimo prebrati datoteko test_de.csv\n",
        "# s posebnim ukazom %time izmerimo čas izvajanja\n",
        "# v read_csv() uporabimo separator '\\t', saj so podatki ločeni s tabulatorjem\n",
        "%time df = pd.read_csv('de/test_de.csv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx8awc5E8m6y",
        "outputId": "b6d57586-e40c-4634-bd97-add99da7fb61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1919561 entries, 0 to 1919560\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Dtype \n",
            "---  ------       ----- \n",
            " 0   userid       object\n",
            " 1   offerid      object\n",
            " 2   countrycode  object\n",
            " 3   category     int64 \n",
            " 4   merchant     object\n",
            " 5   utcdate      object\n",
            " 6   rating       int64 \n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 886.0 MB\n"
          ]
        }
      ],
      "source": [
        "# poglejmo še informacije o naloženi datoteki\n",
        "df.info(memory_usage='deep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHpY3Yrv8m6z"
      },
      "source": [
        "Nalaganje datoteke ``test_de.csv`` je trajalo okoli 10 sekund in pri tem zavzelo 886,0 MB pomnilnika. Poskusimo naložiti datoteko ``train_de.csv``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe_MLITT8m60",
        "outputId": "dc167a3b-b58c-4a3a-bdf4-e491fb9623d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 7s, sys: 9.4 s, total: 1min 16s\n",
            "Wall time: 1min 18s\n"
          ]
        }
      ],
      "source": [
        "%time df = pd.read_csv('de/train_de.csv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZSgXSVr8m61",
        "outputId": "7c690bba-9292-44fd-c3e3-97f95e943fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15844717 entries, 0 to 15844716\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Dtype \n",
            "---  ------       ----- \n",
            " 0   userid       object\n",
            " 1   offerid      object\n",
            " 2   countrycode  object\n",
            " 3   category     int64 \n",
            " 4   merchant     object\n",
            " 5   utcdate      object\n",
            " 6   rating       int64 \n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 7.1 GB\n"
          ]
        }
      ],
      "source": [
        "# še enkrat poglejmo informacije o naloženi datoteki (train_de.csv)\n",
        "df.info(memory_usage='deep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r9VGrpO8m62"
      },
      "source": [
        "Tokrat je nalaganje datoteke trajalo približno 1 minuto in pol, pri tem pa zavzelo 7.1 GB pomnilnika. Jasno vidimo problem velepodatkov - enostavno jih je preveč, da bi lahko obdelali vse naenkrat. Potrebujemo torej način za postopno nalaganje podatkovne zbirke, kjer jo beremo po kosih."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXkNc4BS8m63"
      },
      "source": [
        "## Postopno nalaganje podatkov\n",
        "\n",
        "V Pandas lahko podatke naložimo postopoma po kosih. To dosežemo tako, da v funkcijo ``read_csv()`` podamo parameter ``chunksize``. Število, ki ga podamo kot vrednost, bo določalo koliko vrstic bomo prebrali naenkrat. Poskusimo na datoteki ``train_de.csv``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgBFWFa38m64",
        "outputId": "e88a749a-7335-46f0-9b66-0ed0b8081d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 714 µs, sys: 968 µs, total: 1.68 ms\n",
            "Wall time: 1.69 ms\n"
          ]
        }
      ],
      "source": [
        "# preberimo datoteko train_de.csv po delih (chunksize=50000)\n",
        "%time df = pd.read_csv('de/train_de.csv', sep='\\t', chunksize=50000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqy5AeJ48m64"
      },
      "source": [
        "Tokrat smo prebrali podatke v nekaj milisekundah, kar je bistvena pohitritev.\n",
        "\n",
        "Če uporabimo parameter ``chunksize``, potem rezultat ni več Pandas DataFrame, temveč iterator. Če želimo dostopati do prebranih podatkov, potem moramo to tudi upoštevati. Poglejmo si kako dostopamo do podatkov, ki so bili prebrani po kosih:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sweQwp1d8m64",
        "outputId": "b8d11c59-14ec-49ae-fe2b-ec27650d21e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  userid  \\\n",
            "0      fa937b779184527f12e2d71c711e6411236d1ab59f8597...   \n",
            "1      f6c8958b9bc2d6033ff4c1cc0a03e9ab96df4bcc528913...   \n",
            "2      02fe7ccf1de19a387afc8a11d08852ffd2b4dabaed4e2d...   \n",
            "3      9de5c06d0a16256b13b8e7cdc50bf203ecef533eb5cbe1...   \n",
            "4      8d26ade603ea5473c3844aebfcd9e96e6adc8ff411576e...   \n",
            "...                                                  ...   \n",
            "49995  4ce7facb26d9f9af69e545f6475c63d3c10f990c743499...   \n",
            "49996  0e07f12aec4a43388d70a8cfb8f242faf93478c782307b...   \n",
            "49997  3c37546198bdee4f4daa0103d225568c2d3d5e0fd33a70...   \n",
            "49998  1f996ba4c6b01f5bedb0d31f24e2148ff3f3b5ca5d4233...   \n",
            "49999  1f996ba4c6b01f5bedb0d31f24e2148ff3f3b5ca5d4233...   \n",
            "\n",
            "                                offerid countrycode   category  \\\n",
            "0      c5f63750c2b5b0166e55511ee878b7a3          de  100020213   \n",
            "1      19754ec121b3a99fff3967646942de67          de  100020213   \n",
            "2      5ac4398e4d8ad4167a57b43e9c724b18          de     125801   \n",
            "3      be83df9772ec47fd210b28091138ff11          de     125801   \n",
            "4      3735290a415dc236bacd7ed3aa03b2d5          de     125801   \n",
            "...                                 ...         ...        ...   \n",
            "49995  291643058bc29da316ce6b633739b9b5          de     108701   \n",
            "49996  95f9655beb43dcc26d660a9251a3cd0f          de  100232023   \n",
            "49997  4deac0911842a08233889b3b14eae433          de  100438023   \n",
            "49998  3ec7fda91a57340369d2229a6c13c580          de  100342923   \n",
            "49999  0dccb279b52ad2bb35c57adf594679f0          de  100567613   \n",
            "\n",
            "                                                merchant  \\\n",
            "0      f3c93baa0cf4430849611cedb3a40ec4094d1d370be841...   \n",
            "1      21a509189fb0875c3732590121ff3fc86da770b0628c18...   \n",
            "2      b042951fdb45ddef8ba6075ced0e5885bc2fa4c4470bf7...   \n",
            "3      4740b6c83b6e12e423297493f234323ffd1c991f3d4496...   \n",
            "4      8bf8f87492a799528235c04bb18ff2d12db5058ff6e9a0...   \n",
            "...                                                  ...   \n",
            "49995  b3508cee5c92a9533792fe0a29fdef87a69fc1a928d33e...   \n",
            "49996  86121ab35f24ac3ee205b8dc10c01ee778bdfaf8aaef1d...   \n",
            "49997  3acf8c2704776295abc39ed0a31fc5784f38b42207ede9...   \n",
            "49998  c1d50531fe802776b20a743fb602aa718f5e2146b1cf77...   \n",
            "49999  26467f203f42913b6bc575fd4adc89ad66c5db082c8ab9...   \n",
            "\n",
            "                     utcdate  rating  \n",
            "0      2016-06-14 17:28:47.0       0  \n",
            "1      2016-06-14 17:28:48.0       0  \n",
            "2      2016-06-14 17:28:50.0       0  \n",
            "3      2016-06-14 17:29:19.0       0  \n",
            "4      2016-06-14 17:29:31.0       0  \n",
            "...                      ...     ...  \n",
            "49995  2016-06-04 13:47:55.0       0  \n",
            "49996  2016-06-04 13:48:02.0       0  \n",
            "49997  2016-06-04 13:48:03.0       0  \n",
            "49998  2016-06-04 13:48:14.0       0  \n",
            "49999  2016-06-04 13:48:14.0       0  \n",
            "\n",
            "[50000 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "# preberemo datoteko po kosih\n",
        "iterator = pd.read_csv('de/train_de.csv', sep='\\t', chunksize=50000)\n",
        "\n",
        "for idx, chunk in enumerate(iterator):\n",
        "  if(idx == 0): # izpišemo samo prvi kos (50000 vrstic)\n",
        "    print(chunk) # spremenljivka chunk je DataFrame s podatki (50000 vrstic)\n",
        "  else:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jopkghQ8m65"
      },
      "source": [
        "Z nekaj spremembami zgornje kode lahko dosežemo postopno nalaganje podatkov, ki jih potem tudi obdelamo. Ideja je, da naložimo manjši kos podatkovne zbirke, ga ustrezno obdelamo in shranimo. Če to ponovimo nad vsemi kosi in jih v istem vrstnem redu shranjujemo v novo datoteko, smo uspešno obdelali celotno podatkovno zbirko velepodatkov."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCKWZRM78m65"
      },
      "source": [
        "## Dobre prakse in namigi\n",
        "\n",
        "Kadar se ukvarjamo z velepodatki, si jih želimo optimalno obdelati. Zaradi ogromne velikosti datotek in količine podatkov, je to včasih težko. V nadaljevanju je navedenih nekaj dobrih praks in namigov za delo z velepodatki."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQCLvtHZ8m65"
      },
      "source": [
        "### Predhodno filtriranje velepodatkov\n",
        "\n",
        "Če poznamo strukturo velepodatkov in vemo, da nekaterih stolpcev ne bomo obdelovali, jih lahko pri nalaganju izpustimo. To storimo s funkcijo ``read_csv()`` in parametrom ``usecols``. Kot primer vzemimo stolpce v podatkovni zbirki KASANDR. Če bi nas zanimali zgolj identifikatorji uporabnikov, trgovcev in ocena, bi podatkovno zbirko naložili s spodnjo kodo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SXWb2Ey8m65",
        "outputId": "c74b5ba9-8084-497c-8975-98fba299c461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 38.4 s, sys: 2.01 s, total: 40.5 s\n",
            "Wall time: 41.1 s\n"
          ]
        }
      ],
      "source": [
        "%time df = pd.read_csv('de/train_de.csv', sep='\\t', usecols=['userid', 'merchant', 'rating'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIyPJG-C8m66"
      },
      "source": [
        "V tem primeru smo vseh ~17 milijon vrstic naložili v približno 40 sekundah in pri tem porabili 3.7 GB pomnilnika. To je približno pol manj porabljenega časa in pol manj porabljenega pomnilnika! Vidimo, da je predhodno filtriranje lahko zelo koristno, saj enostavno ohranimo zgolj tiste podatke, katere bomo zagotovo obdelovali."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_w0av6m8m66"
      },
      "source": [
        "#### Kaj pa, če ne poznamo strukture velepodatkov?\n",
        "\n",
        "V primerih, kadar ne poznamo strukture velepodatkov, predhodnega filtriranja velepodatkov ne moremo izvesti takoj, saj ne moremo podati vrednosti za parameter ``usecols``. Kako torej ugotovimo strukturo velepodatkov v datoteki CSV? Če imamo srečo, je struktura podana kot informacija ob datoteki CSV, sicer pa jo lahko z nekaj triki poskusimo ugotoviti.\n",
        "\n",
        "CSV datoteke imajo glavo *(ang. header)*, ki hrani imena stolpcev. Izkaže se, da lahko iz CSV datoteke preberemo zgolj glavo in s tem pridobimo strukturo velepodatkov. To lahko storimo s knjižnico ``csv``, ki je vgrajena v Python. Uporabimo spodnjo kodo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT8wJvyU8m66",
        "outputId": "989e1468-9a04-425e-eec1-5badf15ba5ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 211 µs, sys: 0 ns, total: 211 µs\n",
            "Wall time: 219 µs\n",
            "Struktura podatkovne zbirke KASANDR: ['userid', 'offerid', 'countrycode', 'category', 'merchant', 'utcdate', 'rating']\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "%time reader = csv.DictReader(open('de/train_de.csv', 'r'), delimiter='\\t')\n",
        "\n",
        "print(f'Struktura podatkovne zbirke KASANDR: {reader.fieldnames}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PpBT_KD8m67"
      },
      "source": [
        "Vse skupaj traja manj kot milisekundo, saj ``DictReader`` ne prebere datoteke v celoti. Imena stolpcev najdemo shranjene pod lastnostjo ``fieldnames``.\n",
        "\n",
        "**Opomba:** V tem primeru smo vedeli, da so posamezni atributi v naši datoteki CSV ločeni s tabulatorjem (`` \\t ``). Privzeto je za CSV datoteke znak za ločevanje vejica (``,``). Če res ne vemo nič o podatkovni zbirki, potem nam na tem mestu preostane le, da poskušamo z različnimi ločilnimi znaki.\n",
        "\n",
        "Podobno funkcionalnost nam omogoča tudi knjižnica Pandas. Poglejmo na primeru:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkJdxDA88m67",
        "outputId": "c7ae1b22-c163-4932-8793-2e771f801bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 6 ms, sys: 0 ns, total: 6 ms\n",
            "Wall time: 6.21 ms\n",
            "Struktura podatkovne zbirke KASANDR: ['userid', 'offerid', 'countrycode', 'category', 'merchant', 'utcdate', 'rating']\n"
          ]
        }
      ],
      "source": [
        "%time cols = pd.read_csv('de/train_de.csv', nrows=0, sep='\\t').columns.tolist()\n",
        "\n",
        "print(f'Struktura podatkovne zbirke KASANDR: {cols}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro4dM-rS8m67"
      },
      "source": [
        "V zgornji kodi smo podali parameter ``nrows``, ki določa koliko vrstic s podatki bomo prebrali. Vrednost smo nastavili na 0, saj ne želimo brati podatkov, temveč samo glavo. Dobljen rezultat je podatkovna struktura DataFrame, ki ima lastnost ``columns`` in hrani imena stolpcev. Rezultat s funkcijo ``tolist()`` pretvorimo v seznam. Ta rešitev nam vrne rezultat v približno 10 milisekundah, kar je počasneje kot rešitev z uporabo vgrajene knjižnice ``csv``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRqpVTvq8m68"
      },
      "source": [
        "### Uporaba optimalnih podatkovnih tipov\n",
        "\n",
        "V določenih primerih lahko delo s podatki olajšamo in pohitrimo z uporabo optimalnih podatkovnih tipov. Poglejmo porabo pomnilnika za podatkovne tipe na primeru predhodno filtrirane podatkovne zbirke KASANDR, ki porabi 3,7 GB pomnilnika:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAAM5Xja8m68",
        "outputId": "bfa6d69d-2483-4b74-d384-4b9da89c9ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15844717 entries, 0 to 15844716\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   userid    object\n",
            " 1   merchant  object\n",
            " 2   rating    int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 3.7 GB\n"
          ]
        }
      ],
      "source": [
        "# informacije o predhodno filtrirani podatkovni zbirki KASANDR\n",
        "df.info(memory_usage='deep')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL7zNVqk8m68",
        "outputId": "dcfd458c-9a76-4048-cbb8-ee26aec562e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "userid      object\n",
              "merchant    object\n",
              "rating       int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# izpis podatkovnih tipov\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd3tpyEB8m69",
        "outputId": "ad601349-3af8-4c9f-fb7c-7e1d7ced68ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index              128\n",
              "userid      1917210757\n",
              "merchant    1917210757\n",
              "rating       126757736\n",
              "dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# poraba pomnilnika po podatkovnih tipih\n",
        "df.memory_usage(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4z0xmYJ8m69",
        "outputId": "f3a0589b-3c5d-46f9-d2b4-74fc6f985a79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rating\n",
              "0    15139270\n",
              "1      705447\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# podrobneje poglejmo vrednosti stolpca 'rating'\n",
        "df.value_counts('rating')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFSTJIVB8m69"
      },
      "source": [
        "Iz rezultatov zgornjih treh ukazov vidimo, da stolpca ``userid`` in ``merchant`` (podatkovni tip ``object``) vzameta največ pomnilnika. Stolpec ``rating`` je predstavljen s podatkovnim tipom ``int64``, čeprav se dejansko uporabljata zgolj vrednosti 0 in 1. Stolpca ``userid`` in ``merchant`` sta dobra kandidata za pretvorbo v kategorični tip, stolpec ``rating`` za pretvorbo v bolj primeren podatkovni tip (npr. ``bool``). Naredimo kopijo podatkovne zbirke v pomnilniku in ji določimo optimalne podatkovne tipe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plqhMxHK8m69",
        "outputId": "4a2e3e4d-4f6b-42b7-b175-2257cd4b25dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index             128\n",
              "userid      107102737\n",
              "merchant     31791049\n",
              "rating       15844717\n",
              "dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# kopija podatkovne zbirke v pomnilniku\n",
        "df2 = df.copy()\n",
        "\n",
        "# stolpca 'userid' in 'merchant' pretvorimo v tip 'category'\n",
        "df2['userid'] = df2['userid'].astype('category')\n",
        "df2['merchant'] = df2['merchant'].astype('category')\n",
        "\n",
        "# stolpec 'rating' pretvorimo v tip 'bool'\n",
        "df2['rating'] = df2['rating'].astype('bool')\n",
        "\n",
        "# ponovno preverimo porabo pomnilnika\n",
        "df2.memory_usage(deep=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0JBrmqX8m6-"
      },
      "source": [
        "Po pretvorbi v optimalne podatkovne tipe vidimo, da je poraba pomnilnika bistveno manjša. Natančneje preverimo koliko manjša je poraba pomnilnika:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTnxiPoh8m6-",
        "outputId": "bc6b053d-40ce-41d0-ea57-3e5f993f1a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15844717 entries, 0 to 15844716\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Dtype   \n",
            "---  ------    -----   \n",
            " 0   userid    category\n",
            " 1   merchant  category\n",
            " 2   rating    bool    \n",
            "dtypes: bool(1), category(2)\n",
            "memory usage: 147.6 MB\n"
          ]
        }
      ],
      "source": [
        "df2.info(memory_usage='deep')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZaiL7rH8m6-",
        "outputId": "d8c10f2f-0e86-42fd-c8d8-67348b126854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Izboljšava: 0.04\n"
          ]
        }
      ],
      "source": [
        "diff = df2.memory_usage(deep=True).sum() / df.memory_usage(deep=True).sum()\n",
        "\n",
        "print(f'Izboljšava: {diff:0.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmr_T68E8m6_"
      },
      "source": [
        "Podatkovna zbirka z optimalnimi podatkovnimi tipi zdaj zaseda le 147,6 MB. Podatkovna zbirka z optimalnimi podatkovnimi tipi (``df2``) porabi **4 %** pomnilnika, ki ga porabi predhodno filtrirana podatkovna zbirka (``df``). Zaključimo lahko, da smo drastično pomanjšali pomnilniške zahteve naših velepodatkov z upoštevanjem optimalnih podatkovnih tipov.\n",
        "\n",
        "**Opomba:** alternativno lahko prepustimo knjižnici Pandas, da samodejno optimalno izbere numerične tipe. Poglejmo na primeru:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "V2sSsmW28m6_"
      },
      "outputs": [],
      "source": [
        "# uporaba funkcije to_numeric() za avtomatsko optimalno pretvorbo podatkovnega tipa; rezultat bo tipa 'bool'\n",
        "df2['rating'] = pd.to_numeric(df2['rating'], downcast='unsigned')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-AbkliA8m6_"
      },
      "source": [
        "### Dodatni viri s primeri\n",
        "\n",
        "[Dokumentacija Pandas](https://pandas.pydata.org/docs/user_guide) ima odlične vodiče, katere vam priporočamo, da jih pregledate in preizkusite. Za delo z velepodatki so najbolj relevantni naslednji vodiči, ki jih lahko uporabite kot dodatno gradivo:\n",
        "\n",
        "* [Scaling to large datasets](https://pandas.pydata.org/docs/user_guide/scale.html)\n",
        "* [Sparse data structures](https://pandas.pydata.org/docs/user_guide/sparse.html)\n",
        "* [IO tools (text, CSV, HDF5, ...)](https://pandas.pydata.org/docs/user_guide/io.html)\n",
        "* [Enhancing performance](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
